{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Size_distributions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7ab63bbc6461>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParse_eqn_file\u001b[0m \u001b[0;31m# [•] Needed to parse the .eqn file, name given in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrate_coeff_conversion\u001b[0m \u001b[0;31m# [•] Converts standard text rate coefficients into Numba/Fortran\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mSize_distributions\u001b[0m \u001b[0;31m# [•] Create size distribution according to number of bins and core-material\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Size_distributions'"
     ]
    }
   ],
   "source": [
    "##########################################################################################\n",
    "#                                                                                        #\n",
    "#    Example aerosol phase model [gas+condensed phase]. This takes an equation file,     #\n",
    "#    given in the KPP format,                                                            #\n",
    "#    and then sets up an ODE solver where initial concentrations of any specie can       #\n",
    "#    be set. It also relies on some pre-defined rate coefficients and photolysis rates   #\n",
    "#    taken from the MCM. These are explicitly written into the relevant  modules         #\n",
    "#    in the file Parse_eqn_file.write_rate_file_xxx() which is provided with a           #\n",
    "#    Fortran syntax version of pre-defined rates if that version used [see f2py dir]     #\n",
    "#                                                                                        #\n",
    "#                                                                                        #\n",
    "#    The user specifies a starting size distribution and core material                   #\n",
    "#    The package UManSysProp is then used to calculate properties that dictate           #\n",
    "#    gas-to-particle partitioning. For feature developments and requests, please see     #\n",
    "#    the project wiki.                                                                   #\n",
    "#                                                                                        #\n",
    "#                                                                                        #\n",
    "#    Mixed Python - Fortran version. This version uses the f2py module to re-write       #\n",
    "#    the RHS calculations to exploit multi-core shared/distributed memory machine        #\n",
    "#                                                                                        #\n",
    "#                                                                                        #\n",
    "#    Copyright (C) 2018  David Topping : david.topping@manchester.ac.uk                  #\n",
    "#                                      : davetopp80@gmail.com                            #\n",
    "#    Personal website: davetoppingsci.com                                                #\n",
    "#                                                                                        #\n",
    "#    All Rights Reserved.                                                                #\n",
    "#    This file is part of PyBox.                                                         #\n",
    "#                                                                                        #\n",
    "#    PyBox is free software: you can redistribute it and/or modify it under              #\n",
    "#    the terms of the GNU General Public License as published by the Free Software       #\n",
    "#    Foundation, either version 3 of the License, or (at your option) any later          #\n",
    "#    version.                                                                            #\n",
    "#                                                                                        #\n",
    "#    PyBox is distributed in the hope that it will be useful, but WITHOUT                #\n",
    "#    ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS       #\n",
    "#    FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more              #\n",
    "#    details.                                                                            #\n",
    "#                                                                                        #\n",
    "#    You should have received a copy of the GNU General Public License along with        #\n",
    "#    PyBox.  If not, see <http://www.gnu.org/licenses/>.                                 #\n",
    "#                                                                                        #\n",
    "##########################################################################################\n",
    "# Developed using the Anaconda Python 3 distribution and with the Assimulo ODE solver    # \n",
    "# suite: http://www.jmodelica.org/assimulo                                               #\n",
    "# In the import statements, all files developed specifically for this project            #\n",
    "# as marked [•]                                                                          #\n",
    "##########################################################################################\n",
    "                                                                                     \n",
    "import numpy \n",
    "import os, sys\n",
    "sys.path.append(os.path.abspath('../..'))\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "import Parse_eqn_file # [•] Needed to parse the .eqn file, name given in this file\n",
    "import rate_coeff_conversion # [•] Converts standard text rate coefficients into Numba/Fortran\n",
    "import Size_distributions # [•] Create size distribution according to number of bins and core-material\n",
    "import collections\n",
    "import pdb\n",
    "from datetime import datetime\n",
    "import time\n",
    "#from ODE_solver_opsplit import run_simulation # [•] Contains routines to run ODE solver\n",
    "from ODE_solver import run_simulation # [•] Contains routines to run ODE solver\n",
    "import Property_calculation\n",
    "import pickle\n",
    "# You will also need the UManSysProp package and need to change the directory location of that package\n",
    "# This code relies on UManSysProp to calculate properties - change the link below to where your copy of UManSysProp_public is stored\n",
    "import pybel\n",
    "from shutil import copy2\n",
    "            \n",
    "# Start of the main body of code\n",
    "if __name__=='__main__':\n",
    "   \n",
    "    #-------------------------------------------------------------------------------------\n",
    "    #1)Define starting ambient conditions and species concentrations\n",
    "    #-------------------------------------------------------------------------------------\n",
    "    temp=288.15\n",
    "    RH=0.5 #RH/100%\n",
    "    PInit=98000 #Pascals - Starting pressure of parcel expansion [if run in Parcel model mode]\n",
    "    #Define a start time \n",
    "    hour_of_day=12.0\n",
    "    start_time=hour_of_day*60*60 # seconds, used as t0 in solver\n",
    "    simulation_time= 3600.0 # seconds\n",
    "    batch_step=300.0 # seconds\n",
    "    #Convert RH to concentration of water vapour molecules [this will change when in Parcel model mode]\n",
    "    temp_celsius=temp-273.15\n",
    "    # Saturation VP of water vapour, to get concentration of H20\n",
    "    Psat=610.78*numpy.exp((temp_celsius/(temp_celsius+238.3))*17.2694)\n",
    "    Pw=RH*Psat\n",
    "    Updraft=0.0\n",
    "    Wconc=0.002166*(Pw/(temp_celsius+273.16)) #kg/m3\n",
    "    #Convert from m3 to cm3\n",
    "    Wconc=Wconc*1.0e-6\n",
    "    #Convert from kg to molecules/cc\n",
    "    H2O=Wconc*(1.0/(18.0e-3))*6.0221409e+23\n",
    "    \n",
    "    #-------------------------------------------------------------------------------------\n",
    "    #2) General aerosol partitioning constants\n",
    "    #-------------------------------------------------------------------------------------\n",
    "    Lv_water_vapour=2.5e3 # Latent heat of vapourisation of water [J/g] \n",
    "    Rv=461.0 #Individual gas constant of water vapour [J/Kg.K]\n",
    "    Ra=287.0 #Gas constant for dry air [J/Kg.K]\n",
    "    R_gas=8.3144598 #Ideal gas constant [kg m2 s-2 K-1 mol-1]\n",
    "    R_gas_other=8.2057e-5 #Ideal gas constant [m3 bar K-1 mol-1]\n",
    "    GRAV=9.8; #Gravitational acceleration [(m/2)2]\n",
    "    cp=1005; #Specific heat capacity of air [J/Kg.K]\n",
    "    sigma=72.0e-3 # Assume surface tension of water (mN/m)\n",
    "    NA=6.0221409e+23 #Avogadros number\n",
    "    kb=1.380648E-23 #Boltzmanns constant\n",
    "    \n",
    "    #-------------------------------------------------------------------------------------\n",
    "    # 3) Choose methods used for calculating properties that dictate gas-to-particle partitioning\n",
    "    #-------------------------------------------------------------------------------------\n",
    "    # The default are set below, with options given \n",
    "    # More information on each method can be found on the UManSysProp website and/or the source code\n",
    "    vp_method='nannoolal' # Saturation vapour pressure ['nannoolal': 'myrdal_and_yalkowsky': 'evaporation']\n",
    "    bp_method='joback_and_reid' # Boiling point ['joback_and_reid': 'stein_and_brown': 'nannoolal']\n",
    "    critical_method='nannoolal' # Critical properties for density ['nannoolal':'joback_and_reid']\n",
    "    density_method='girolami' # Pure component liquid density ['girolami': 'schroeder':'le_bas':'tyn_and_calus']\n",
    "    # Some species will have no vapour pressure data associaed with them by using the .xml file. This\n",
    "    # includes oxidants. These are then ignored in the partitioning calculations. In addtion, you\n",
    "    # can also define a calulated vapour pressure above which partitioning can be ignored. This should\n",
    "    # be set to a relatively high value, given calculated values are given in Log10(atmospehres). By doing this you\n",
    "    # can significantly decrease the size of of the resultant jacobian and speed-up calculations\n",
    "    # This information is compiled in the call to Property_calculation.Pure_component1\n",
    "    ignore_vp=True\n",
    "    vp_cutoff=-6.0\n",
    "    \n",
    "    #-------------------------------------------------------------------------------------\n",
    "    # 4) Parse equation file \n",
    "    #-------------------------------------------------------------------------------------\n",
    "    # Do files already exist? If so, you can bypass this stage and proceed with simulation\n",
    "    # Note, this is for you to manage. If unsure which files are available, re-parse and re-compile\n",
    "    # This is important since the species-2-dict array maps extracted species to array numbers. This\n",
    "    # can change with each parse\n",
    "    \n",
    "    # First we load the files that deal only with the gas phase mechanism\n",
    "\n",
    "    filename='MCM_APINENE'    \n",
    "\n",
    "    files_exist = False\n",
    "    \n",
    "    if files_exist is False:\n",
    "\n",
    "        # Delete any 'straggling' f90 or cython files\n",
    "        for fname in os.listdir('.'):\n",
    "            #if \"f2py.cpython\" in fname:\n",
    "            #    os.remove(fname)\n",
    "            if \".f90\" in fname:\n",
    "                os.remove(fname)\n",
    "                \n",
    "        for fname in os.listdir('.'):\n",
    "            if \".npy\" in fname:\n",
    "                os.remove(fname)\n",
    "            if \".pickle\" in fname:\n",
    "                os.remove(fname)\n",
    "            if \".npz\" in fname:\n",
    "                os.remove(fname)\n",
    "            if \".eqn.txt\" in fname:\n",
    "                os.remove(fname)\n",
    "\n",
    "        # Copy mechanism file into working directory\n",
    "        copy2('../../mechanism_files/'+filename+'.eqn.txt','.')\n",
    "                \n",
    "        # Parse equation file and store relevant dictionaries for later retrieval\n",
    "        print_options=dict()\n",
    "        print_options['Full_eqn']=0 #Set to 1 to print details of all equations and rate coefficients parsed [useful for checking]\n",
    "\n",
    "        # Define the .eqn file to be used in the following\n",
    "        outputdict=Parse_eqn_file.extract_mechanism(filename+'.eqn.txt',print_options)\n",
    "        \n",
    "        # Now map these species onto SMILES according to the relevant .xml file that comes with the MCM. If this file changes\n",
    "        # you will need to change the reference here\n",
    "        outputdict=Parse_eqn_file.extract_smiles_species(outputdict,'../MCM.xml')\n",
    "\n",
    "        # Collect the dictionaries generated\n",
    "        #reaction_dict=outputdict['reaction_dict']\n",
    "        rate_dict=outputdict['rate_dict']\n",
    "        rate_dict_fortran=rate_coeff_conversion.convert_rate_mcm_fortran(rate_dict)\n",
    "        rate_dict_reactants=outputdict['rate_dict_reactants']\n",
    "        #rate_def=outputdict['rate_def']\n",
    "        loss_dict=outputdict['loss_dict']\n",
    "        gain_dict=outputdict['gain_dict']\n",
    "        stoich_dict=outputdict['stoich_dict']\n",
    "        species_dict=outputdict['species_dict']\n",
    "        species_dict2array=outputdict['species_dict2array']\n",
    "        equations=outputdict['max_equations']\n",
    "        Pybel_object_dict=outputdict['Pybel_object_dict'] # Might be different size to mechanism extracted dicts [due to ignoring oxidants etc]\n",
    "        SMILES_dict=outputdict['SMILES_dict']\n",
    "        num_species=len(species_dict.keys())\n",
    "        \n",
    "        # Now calculate all properties that dictate gas-to-particle partitioning\n",
    "        print(\"Calculating properties that dictate gas-to-particle partitioning\")\n",
    "        property_dict1=Property_calculation.Pure_component1(num_species,species_dict,\n",
    "            species_dict2array,Pybel_object_dict,SMILES_dict,temp,vp_method,bp_method,\n",
    "            critical_method,density_method,ignore_vp,vp_cutoff)\n",
    "        \n",
    "        #pdb.set_trace()\n",
    "        print(\"Saving the mechanism and property dictionaries as a pickled object for later retrieval\")\n",
    "        # save the dictionary to a file for later retrieval - have to do each seperately.\n",
    "        with open(filename+'_species_dict2array.pickle', 'wb') as handle:\n",
    "            pickle.dump(species_dict2array, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        with open(filename+'_species_dict.pickle', 'wb') as handle:\n",
    "            pickle.dump(species_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        with open(filename+'_Pybel_object_dict.pickle', 'wb') as handle:\n",
    "            pickle.dump(Pybel_object_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        with open(filename+'_SMILES_dict.pickle', 'wb') as handle:\n",
    "            pickle.dump(SMILES_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        #with open(filename+'_property_dict1.pickle', 'wb') as handle:\n",
    "        #    pickle.dump(property_dict1, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        #with open(filename+'_property_dict2.pickle', 'wb') as handle:\n",
    "        #    pickle.dump(property_dict2, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        with open(filename+'_num_species_gas.pickle', 'wb') as handle:\n",
    "            pickle.dump(num_species, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "        # Generate some static Fortran libraries for use in ODE solver\n",
    "        # Here you have the option to use OpenMP for spreading caclualtions across available cores\n",
    "        openMP=False\n",
    "        # Please note, this has not yet been optimised and remains experimental. The default is to\n",
    "        # not use OpenMP but keep the 'flag' in response to a fully profiled and optimised model version\n",
    "    \n",
    "        #pdb.set_trace()\n",
    "    \n",
    "        # Convert the rate coefficient expressions into Fortran commands\n",
    "        print(\"Converting rate coefficient operation into Fortran file\")\n",
    "        #rate_dict=rate_coeff_conversion.convert_rate_mcm(rate_dict)\n",
    "        # Convert rate definitions in original *.eqn.txt file into a form to be used in Fortran\n",
    "        rate_dict_fortran=rate_coeff_conversion.convert_rate_mcm_fortran(rate_dict)\n",
    "        Parse_eqn_file.write_rate_file_fortran(filename,rate_dict_fortran,openMP)    \n",
    "        print(\"Compiling rate coefficient file using f2py\")\n",
    "        #Parse_eqn_file.write_rate_file(filename,rate_dict,mcm_constants_dict)\n",
    "        #os.system(\"python f2py_rate_coefficient.py build_ext --inplace --fcompiler=gfortran\")\n",
    "        os.system('f2py -c -m rate_coeff_f2py Rate_coefficients.f90 --f90flags=\"-O3 -ffast-math -fopenmp\" -lgomp')\n",
    "        \n",
    "        # Create Fortran file for calculating prodcts all of reactants for all reactions\n",
    "        print(\"Creating Fortran file to calculate reactant contribution to equation\")\n",
    "        Parse_eqn_file.write_reactants_indices_fortran(filename,equations,species_dict2array,rate_dict_reactants,loss_dict,openMP)\n",
    "        print(\"Compiling reactant product file using f2py\")\n",
    "        #os.system(\"python f2py_reactant_conc.py build_ext --inplace --fcompiler=gfortran\")\n",
    "        os.system('f2py -c -m reactants_conc_f2py Reactants_conc.f90 --f90flags=\"-O3 -ffast-math -fopenmp\" -lgomp')\n",
    "        \n",
    "        # Create Fortran file for calculating dy_dt\n",
    "        print(\"Creating Fortran file to calculate dy_dt for each reaction\")\n",
    "        Parse_eqn_file.write_loss_gain_fortran(filename,equations,num_species,loss_dict,gain_dict,species_dict2array,openMP)\n",
    "        print(\"Compiling dydt file using f2py\")\n",
    "        #os.system(\"python f2py_loss_gain.py build_ext --inplace --fcompiler=gfortran\")\n",
    "        os.system('f2py -c -m loss_gain_f2py Loss_Gain.f90 --f90flags=\"-O3 -ffast-math -fopenmp\" -lgomp')\n",
    "                \n",
    "        # Create .npy file with indices for all RO2 species\n",
    "        print(\"Creating file that holds RO2 species indices\")\n",
    "        Parse_eqn_file.write_RO2_indices(filename,species_dict2array)\n",
    "        \n",
    "        # Create jacobian \n",
    "        #Parse_eqn_file.write_gas_jacobian_fortran(filename,equations,num_species,loss_dict,gain_dict,species_dict2array,rate_dict_reactants,openMP)\n",
    "        #print(\"Compiling jacobian function using f2py\")      \n",
    "        #os.system(\"python f2py_jacobian.py build_ext --inplace\")\n",
    "\n",
    "    else:\n",
    "        \n",
    "        # You have already parsed the .eqn file and stored relevant information. \n",
    "        # Load the dictioanties here to pass into the ODE solver\n",
    "        with open(filename+'_species_dict2array.pickle', 'rb') as f:\n",
    "            species_dict2array = pickle.load(f) \n",
    "        with open(filename+'_species_dict.pickle', 'rb') as f:\n",
    "            species_dict = pickle.load(f) \n",
    "        with open(filename+'_equations.pickle', 'rb') as f:\n",
    "            equations = pickle.load(f) \n",
    "        with open(filename+'_Pybel_object_dict.pickle', 'rb') as f:\n",
    "            Pybel_object_dict= pickle.load(f) \n",
    "        with open(filename+'_SMILES_dict.pickle', 'rb') as f:\n",
    "            SMILES_dict= pickle.load(f) \n",
    "        #with open(filename+'_property_dict1.pickle', 'rb') as f:\n",
    "        #    property_dict1= pickle.load(f) \n",
    "        #with open(filename+'_property_dict2.pickle', 'rb') as f:\n",
    "        #    property_dict2= pickle.load(f) \n",
    "        with open(filename+'_num_species_gas.pickle', 'rb') as f:\n",
    "            num_species= pickle.load(f) \n",
    "            \n",
    "        print(\"Calculating properties that dictate gas-to-particle partitioning\")\n",
    "        property_dict1=Property_calculation.Pure_component1(num_species,species_dict,\n",
    "            species_dict2array,Pybel_object_dict,SMILES_dict,temp,vp_method,bp_method,\n",
    "            critical_method,density_method,ignore_vp,vp_cutoff)\n",
    "\n",
    "    #-------------------------------------------------------------------------------------    \n",
    "    # 5) Modify property arrays to include water as partitioning component\n",
    "    #-------------------------------------------------------------------------------------\n",
    "    # Load previously calculated values, and shave off components IF ignore_vp is True\n",
    "    y_density_array=property_dict1['y_density_array']\n",
    "    y_mw=property_dict1['y_mw']\n",
    "    sat_vp=property_dict1['sat_vp']\n",
    "    Delta_H=property_dict1['Delta_H']\n",
    "    Latent_heat_gas=property_dict1['Latent_heat_gas']   \n",
    "    ignore_index=property_dict1['ignore_index'] \n",
    "    ignore_index_fortran=property_dict1['ignore_index_fortran'] \n",
    "    include_index=sorted(property_dict1['include_index']) # This is an array that captures compounds to be included in the partitioning calculations\n",
    "    #pdb.set_trace()\n",
    "    if ignore_vp is True: # Remove those comounds for which there is no vapour pressure data OR are too volatile \n",
    "        y_density_array=numpy.array(y_density_array)[include_index].tolist()\n",
    "        y_mw=numpy.array(y_mw)[include_index].tolist()\n",
    "        sat_vp=numpy.array(sat_vp)[include_index].tolist()\n",
    "        Delta_H=numpy.array(Delta_H)[include_index].tolist()\n",
    "        Latent_heat_gas=numpy.array(Latent_heat_gas)[include_index].tolist()\n",
    "        \n",
    "    \n",
    "    sat_vap_water = numpy.exp((-0.58002206E4 / temp) + 0.13914993E1 - (0.48640239E-1 * temp) + (0.41764768E-4 * (temp**2.0E0))- (0.14452093E-7 * (temp**3.0E0)) + (0.65459673E1 * numpy.log(temp)))\n",
    "    y_density_array.append(1000.0E0) #Append density of water to array [kg/m3]\n",
    "    y_mw.append(18.0E0) #Append mw of water to array [g/mol]\n",
    "    sat_vp.append(numpy.log10(sat_vap_water*9.86923E-6)) #Convert Pa to atm\n",
    "    Delta_H.append(40.66)\n",
    "    Latent_heat_gas.append(Lv_water_vapour) #Water vapour, taken from Paul Connolly's parcel model ACPIM\n",
    "    num_species+=1 #We need to increase the number of species to account for water in the gas phase\n",
    "    # Now also account for any change in species considered in condensed phase based on those that are ignored\n",
    "    num_species_condensed=len(y_density_array)\n",
    "    #Update the Pybel object libraries\n",
    "    key=pybel.readstring('smi','O')\n",
    "    Pybel_object_dict.update({'O':key})\n",
    "    #Pybel_object_activity.update({key:Water_Abun})\n",
    "    species_dict2array.update({'H2O':num_species-1})\n",
    "    include_index.append(num_species-1)\n",
    "    #pdb.set_trace()\n",
    "    ignore_index_fortran=numpy.append(ignore_index_fortran,0.0)\n",
    "    #pdb.set_trace()\n",
    "    #-------------------------------------------------------------------------------------\n",
    "    # 6) Now calculate the additional properties that dictate gas-to-particle partitioning [inc water]\n",
    "    #-------------------------------------------------------------------------------------\n",
    "    property_dict2=Property_calculation.Pure_component2(num_species_condensed,y_mw,R_gas,temp)\n",
    "    alpha_d_org=property_dict2['alpha_d_org']\n",
    "    DStar_org=property_dict2['DStar_org']\n",
    "    mean_them_vel=property_dict2['mean_them_vel']\n",
    "    gamma_gas=property_dict2['gamma_gas']\n",
    "    \n",
    "    # Now deal with the files that treat gas-to-particle partitioning\n",
    "    \n",
    "    #-------------------------------------------------------------------------------------\n",
    "    # 7) Define species concetrations     \n",
    "    #-------------------------------------------------------------------------------------\n",
    "    # Define initial concentrations, in pbb, of species using names from KPP file\n",
    "    species_initial_conc=dict()\n",
    "    species_initial_conc['O3']=18.0\n",
    "    species_initial_conc['APINENE']=30.0\n",
    "    #species_initial_conc['BCARY']=20.0\n",
    "\n",
    "    # Add water\n",
    "    species_initial_conc['H2O']=H2O\n",
    "\n",
    "    #-------------------------------------------------------------------------------------\n",
    "    # 8) Define an initial size distribution. \n",
    "    #-------------------------------------------------------------------------------------\n",
    "    #     This also defines an initial\n",
    "    #     concentration of core material. This core material can either be\n",
    "    #     an inert absorptive mass, or have specified SMARTS as organic or\n",
    "    #     inorganic component. Presently we only have 1 core and it is assumed\n",
    "    #     involatile.    \n",
    "    #Please note that the size distribution module has been replicated from\n",
    "    #http://all-geo.org/volcan01010/2013/09/how-to-use-lognormal-distributions-in-python/\n",
    "    num_bins=16 #Number of size bins\n",
    "    y_cond=[0.0]*num_species_condensed*num_bins #array that contains all species in all bins\n",
    "                                      #water is the final component\n",
    "    total_conc=100 #Total particles per cc\n",
    "    std=2.2 #Standard Deviation\n",
    "    lowersize=0.01 #microns\n",
    "    uppersize=1.0 #microns\n",
    "    meansize=0.2 #microns\n",
    "    #Create a number concentration for a lognormal distribution\n",
    "    N_perbin,x=Size_distributions.lognormal(num_bins,total_conc,meansize,std,lowersize,uppersize)\n",
    "    print (\"Starting sizes = \", x)\n",
    "    #Plot the discretized size distribution - Close the figure to proceed\n",
    "    total_number=sum(N_perbin)\n",
    "\n",
    "    # - Specify the core material. \n",
    "    # This code is currently setup to consider ammonium sulphate as the core\n",
    "    y_core=[1.0e-3]*num_bins #Will hold concentration of core material, only initialise here [molecules/cc] \n",
    "    core_density_array=[1770.0]*num_bins #[kg/m3] - need to make sure this matches core definition above\n",
    "    core_mw=[132.14]*num_bins #[g/mol]\n",
    "    #Calculate a concentration, in molecules per cc, per size bin of the involatile material\n",
    "    #The size bins, 'x', are given in microns. \n",
    "    core_type='Inorganic' #Label to be used in non-ideal model variants. It is useful to\n",
    "    #Define the SMARTS representations of relevant ions for use in proeeding calculations. These can be\n",
    "    #seleted from the following:\n",
    "    #[Na+] Sodium cation\n",
    "    #[NH4+] Ammonium cation\n",
    "    #[K+] Potassium cation\n",
    "    #[Ca+2] Calcium cation\n",
    "    #[Mg+2] Magnesium cation\n",
    "    #[Cl-] Chloride anion\n",
    "    #[O-][N+]([O-])=O Nitrate anion\n",
    "    #[O-]S([O-])(=O)=O Sulphate anion\n",
    "    key_ion1=pybel.readstring('smi','[NH4+]')\n",
    "    key_ion2=pybel.readstring('smi','[O-]S([O-])(=O)=O')\n",
    "    ammonium_key=key_ion1\n",
    "    sulphate_key=key_ion2\n",
    "    #Update the species_dict2array to include the ions\n",
    "    species_dict2array.update({ammonium_key:num_species})\n",
    "    species_dict2array.update({sulphate_key:num_species+1})\n",
    "    cation_index=[0] #used to extract ion concentrations from within the simulation - use order from above [defunct for now]\n",
    "    anion_index=[1]\n",
    "    \n",
    "    core_dissociation=3.0 #Define this according to choice of core type. Please note this value might change\n",
    "    y_core=(4.0/3.0)*numpy.pi*numpy.power(numpy.array(x*1.0e-6),3.0) #4/3*pi*radius^3\n",
    "    y_core=y_core*numpy.array(core_density_array) #mass per particle [kg]\n",
    "    y_core=y_core/(numpy.array(core_mw)*1.0e-3) #moles per particle, changing mw from g/mol to kg/mol\n",
    "    y_core=y_core*NA #molecules per particle\n",
    "    y_core=y_core*numpy.array(N_perbin) #molecules/cc representing each size range\n",
    "    #Calculate a core mass based on the above information [converting from molecules/cc to micrograms/m3]    \n",
    "    core_mass=numpy.sum(numpy.multiply(numpy.array(y_core)/NA,numpy.array(core_mw)))*1.0E12\n",
    "    print (\"'Dry' core mass = \", core_mass)\n",
    "    #4) Initialise some water across the distribution according to the starting RH. \n",
    "    step=0\n",
    "    #In the following we need to add water to the last element of every size bin chunk of the array\n",
    "    for radius in x:\n",
    "        water_moles=(y_core[step]*core_dissociation)*(RH/(1.0E0-RH))\n",
    "        y_cond[(num_species_condensed-1)+(step*num_species_condensed)]=water_moles #Add this water to the distribution. \n",
    "        #                                                       Note this dosnt yet account for a kelvin factor\n",
    "        step+=1\n",
    "        \n",
    "    #-------------------------------------------------------------------------------------\n",
    "    # 9) Create partitioning module if it dosnt exist\n",
    "    # IMPORTANT - if you change the number of size bins this needs re-compiling\n",
    "    #-------------------------------------------------------------------------------------\n",
    "    if files_exist is False: # This needs to be changed if either num_species OR num_bins changes\n",
    "                             # Future versions should add ability to only change number of bins\n",
    "\n",
    "        # Create a Fortran file for calculating gas-to-particle partitioning drivers\n",
    "        print(\"Creating Fortran file to calculate gas-to-particle partitining for each compound\")\n",
    "        Parse_eqn_file.write_partitioning_section_fortran_ignore(num_species+num_species_condensed*num_bins,num_bins,num_species,num_species_condensed,include_index)\n",
    "        print(\"Compiling gas-to-particle partitioning file using f2py\")\n",
    "        #os.system(\"python f2py_partition.py build_ext --inplace --fcompiler=gfortran\")    \n",
    "        os.system('f2py -c -m partition_f2py Partitioning.f90 --f90flags=\"-O3 -ffast-math -fopenmp\" -lgomp')\n",
    "\n",
    "    #-------------------------------------------------------------------------------------\n",
    "    # 10) Save this information to a dictionary to pass to ODE solver\n",
    "    #-------------------------------------------------------------------------------------\n",
    "    \n",
    "    input_dict=dict()\n",
    "    input_dict['species_dict']=species_dict\n",
    "    input_dict['species_dict2array']=species_dict2array\n",
    "    input_dict['species_initial_conc']=species_initial_conc\n",
    "    input_dict['equations']=equations\n",
    "    input_dict['num_species']=num_species\n",
    "    input_dict['num_species_condensed']=num_species_condensed\n",
    "    input_dict['y_density_array_asnumpy']=numpy.array(y_density_array)\n",
    "    input_dict['y_mw']=numpy.array(y_mw)\n",
    "    input_dict['sat_vp']=sat_vp\n",
    "    input_dict['Delta_H']=Delta_H\n",
    "    input_dict['Latent_heat_asnumpy']=numpy.array(Latent_heat_gas)\n",
    "    input_dict['DStar_org_asnumpy']=numpy.array(DStar_org)\n",
    "    input_dict['alpha_d_org_asnumpy']=numpy.array(alpha_d_org)\n",
    "    input_dict['gamma_gas_asnumpy']=numpy.array(gamma_gas)\n",
    "    input_dict['Updraft']=Updraft\n",
    "    input_dict['GRAV']=GRAV\n",
    "    input_dict['Rv']=Rv\n",
    "    input_dict['Ra']=Ra\n",
    "    input_dict['R_gas']=R_gas\n",
    "    input_dict['R_gas_other']=R_gas_other\n",
    "    input_dict['cp']=cp\n",
    "    input_dict['sigma']=sigma\n",
    "    input_dict['NA']=NA\n",
    "    input_dict['kb']=kb\n",
    "    input_dict['Lv_water_vapour']=Lv_water_vapour\n",
    "    input_dict['ignore_index']=ignore_index\n",
    "    input_dict['ignore_index_fortran']=ignore_index_fortran\n",
    "    input_dict['ycore_asnumpy']=numpy.array(y_core)\n",
    "    input_dict['core_density_array_asnumpy']=numpy.array(core_density_array)\n",
    "    input_dict['y_cond_initial']=y_cond\n",
    "    input_dict['num_bins']=num_bins\n",
    "    input_dict['core_molw_asnumpy']=numpy.array(core_mw)\n",
    "    input_dict['core_dissociation']=core_dissociation\n",
    "    input_dict['N_perbin']=N_perbin\n",
    "    input_dict['include_index']=include_index\n",
    "    \n",
    "    RO2_indices=numpy.load(filename+'_RO2_indices.npy')    \n",
    "    \n",
    "    #pdb.set_trace()\n",
    "\n",
    "    #Do you want to save the output from the simulation as a .npy file?\n",
    "    save_output=True\n",
    "    plot_mass=True\n",
    "    #-------------------------------------------------------------------------------------\n",
    "    # 11) Run the simulation\n",
    "    run_simulation(filename, save_output, start_time, temp, RH, RO2_indices, H2O, PInit, y_cond, input_dict, simulation_time, batch_step, plot_mass)\n",
    "    #-------------------------------------------------------------------------------------\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/PyBox\n"
     ]
    }
   ],
   "source": [
    "print(os.path.abspath('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
